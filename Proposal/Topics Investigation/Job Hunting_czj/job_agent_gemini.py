# -*- coding: utf-8 -*-

"""
Job Seeking Agent (Version 4.0 - Final Fix)

æ­¤ç‰ˆæœ¬æ ¹æ® debug_page_source.html çš„å†…å®¹ï¼Œ
æ›´æ–°äº† BeautifulSoup çš„ CSS é€‰æ‹©å™¨ï¼Œä»¥åŒ¹é…ç½‘ç«™æœ€æ–°çš„ HTML ç»“æ„ã€‚
è¿™æ˜¯ç½‘é¡µæŠ“å–ä¸­éå¸¸å¸¸è§çš„ç»´æŠ¤æ­¥éª¤ã€‚
"""

import os
import requests
from bs4 import BeautifulSoup
import google.generativeai as genai
import textwrap
import time

# --- ç”¨äº Selenium ç½‘é¡µè‡ªåŠ¨åŒ–çš„åº“ ---
from selenium import webdriver
from selenium.webdriver.chrome.service import Service as ChromeService
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException

# --- 1. é…ç½® AI æ¨¡å‹ ---
api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    raise ValueError("è¯·è®¾ç½® 'GOOGLE_API_KEY' ç¯å¢ƒå˜é‡ã€‚")
genai.configure(api_key=api_key)
llm = genai.GenerativeModel('gemini-pro')

# --- 2. åˆ›å»ºä¸€ä¸ªè™šæ‹Ÿç®€å†æ–‡ä»¶ (ç”¨äºæ¼”ç¤º) ---
resume_content = """
ç‹å°æ˜
ç”µè¯: 138-0013-8000 | é‚®ç®±: xiaoming.wang@email.com | GitHub: github.com/xiaomingw

### æ•™è‚²èƒŒæ™¯
- åå—ç§‘æŠ€å¤§å­¦, è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯å­¦å£« (2018 - 2022)
  - GPA: 3.7/4.0
  - ç›¸å…³è¯¾ç¨‹: æ•°æ®ç»“æ„ã€ç®—æ³•ã€æ“ä½œç³»ç»Ÿã€è®¡ç®—æœºç½‘ç»œ

### é¡¹ç›®ç»å†
1. **ä¸ªäººåšå®¢ç³»ç»Ÿ (2021)**
   - ä½¿ç”¨ Python Django æ¡†æ¶å’Œ SQLite æ•°æ®åº“å¼€å‘äº†ä¸€ä¸ªåŠŸèƒ½å®Œæ•´çš„åšå®¢å¹³å°ã€‚
   - å®ç°äº†æ–‡ç« å‘å¸ƒã€è¯„è®ºã€ç”¨æˆ·è®¤è¯ç­‰åŸºæœ¬åŠŸèƒ½ã€‚
   - é€šè¿‡è¿™ä¸ªé¡¹ç›®ç†Ÿæ‚‰äº† Web å¼€å‘çš„åŸºæœ¬æµç¨‹å’Œ MVC è®¾è®¡æ¨¡å¼ã€‚

2. **æ ¡å›­äºŒæ‰‹ä¹¦äº¤æ˜“å¹³å° (è¯¾ç¨‹è®¾è®¡, 2022)**
   - ä¸€ä¸ªç®€å•çš„Webåº”ç”¨ï¼Œå…è®¸å­¦ç”Ÿå‘å¸ƒå’Œæœç´¢äºŒæ‰‹ä¹¦ç±ä¿¡æ¯ã€‚
   - æˆ‘è´Ÿè´£åç«¯å¼€å‘ï¼Œä½¿ç”¨ Flask æ¡†æ¶å’Œ SQLAlchemyã€‚
   - å­¦ä¹ äº† RESTful API çš„åŸºæœ¬è®¾è®¡åŸåˆ™ã€‚

### æŠ€èƒ½æ¸…å•
- **ç¼–ç¨‹è¯­è¨€**: ç²¾é€š Python, ç†Ÿæ‚‰ Java å’Œ C++
- **Webæ¡†æ¶**: ç†Ÿæ‚‰ Django å’Œ Flask
- **æ•°æ®åº“**: äº†è§£ SQL, ä½¿ç”¨è¿‡ SQLite å’Œ MySQL
- **å·¥å…·**: Git, Docker (åˆçº§)
"""
with open("resume.txt", "w", encoding='utf-8') as f:
    f.write(resume_content)

# -----------------------------------------------------------------------------
# Agent ä¸»ç±»
# -----------------------------------------------------------------------------
class JobSeekingAgent:
    def __init__(self, llm_model):
        self.llm = llm_model
        self.resume_text = ""
        self.job_postings = []
        print("ğŸ¤– æ±‚èŒAgentå·²å¯åŠ¨ï¼")

    def load_resume(self, resume_path="resume.txt"):
        try:
            with open(resume_path, 'r', encoding='utf-8') as f:
                self.resume_text = f.read()
            print("ğŸ“„ ç®€å†åŠ è½½æˆåŠŸã€‚")
        except FileNotFoundError:
            print(f"é”™è¯¯: ç®€å†æ–‡ä»¶ {resume_path} æœªæ‰¾åˆ°ã€‚")
            exit()

    # -----------------------------------------------------------------------------
    # Tool 1: èŒä½ä¿¡æ¯æœç´¢ (Selenium Version) - æœ€ç»ˆä¿®æ­£ç‰ˆ
    # -----------------------------------------------------------------------------
    def tool_search_jobs(self, query: str, num_jobs: int = 5) -> list:
        query = query.replace(' ', '+')
        url = f"https://weworkremotely.com/remote-jobs/search?term={query}"
        print(f"\nğŸ” [Selenium] æ­£åœ¨å¯åŠ¨æµè§ˆå™¨å¹¶æœç´¢ '{query}' çš„èŒä½...")

        options = webdriver.ChromeOptions()
        options.add_argument("--headless")
        options.add_argument("--no-sandbox")
        options.add_argument("--disable-dev-shm-usage")
        options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36")
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option('useAutomationExtension', False)
        options.add_argument("--disable-blink-features=AutomationControlled")

        driver = None
        try:
            service = ChromeService(ChromeDriverManager().install())
            driver = webdriver.Chrome(service=service, options=options)
            driver.get(url)
            
            # ç­‰å¾…èŒä½åˆ—è¡¨å®¹å™¨ section.jobs å‡ºç°
            wait = WebDriverWait(driver, 15)
            wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "section.jobs li")))
            
            page_html = driver.page_source
            soup = BeautifulSoup(page_html, 'html.parser')

        except TimeoutException:
            print("âŒ é¡µé¢åŠ è½½è¶…æ—¶æˆ–æœªæ‰¾åˆ°èŒä½åˆ—è¡¨å®¹å™¨ã€‚")
            if driver:
                driver.save_screenshot("debug_screenshot.png")
                with open("debug_page_source.html", "w", encoding='utf-8') as f:
                    f.write(driver.page_source)
                print("â„¹ï¸ å·²ä¿å­˜æˆªå›¾å’Œé¡µé¢æºç ä¾›åˆ†æã€‚")
                driver.quit()
            return []
        except Exception as e:
            print(f"âŒ Selenium è¿è¡Œæ—¶å‘ç”Ÿé”™è¯¯: {e}")
            if driver:
                driver.quit()
            return []

        # --- ã€å…³é”®ä¿®æ”¹: æ›´æ–°è§£æé€»è¾‘ä»¥åŒ¹é…æ–°HTMLç»“æ„ã€‘---
        scraped_jobs = []
        jobs_list_container = soup.find('section', class_='jobs')
        
        if jobs_list_container:
            # é€‰æ‹©æ‰€æœ‰ class åŒ…å« 'new-listing-container' çš„ <li> æ ‡ç­¾
            job_items = jobs_list_container.select('li.new-listing-container')

            for item in job_items[:num_jobs]:
                # æ ¹æ®æ–°çš„HTMLç»“æ„æå–ä¿¡æ¯
                title_element = item.select_one('h3.new-listing__header__title')
                company_element = item.select_one('p.new-listing__company-name')
                # èŒä½è¯¦æƒ…é“¾æ¥æ˜¯ li æ ‡ç­¾ä¸‹çš„ç¬¬äºŒä¸ª a æ ‡ç­¾
                link_element = item.select_one('a[href*="/remote-jobs/"]')
                
                if title_element and company_element and link_element:
                    title = title_element.text.strip()
                    company = company_element.text.strip()
                    job_link = "https://weworkremotely.com" + link_element['href']
                    
                    scraped_jobs.append({
                        "title": title,
                        "company": company,
                        "description": f"èŒä½: {title}\nå…¬å¸: {company}\nè¯¦æƒ…è¯·è®¿é—®: {job_link}\n(æ³¨æ„: ä¸ºæé«˜æ•ˆç‡, æœªçˆ¬å–è¯¦ç»†æè¿°, AIå°†åŸºäºæ­¤ä¿¡æ¯è¿›è¡Œåˆ†æ)"
                    })
        
        if not scraped_jobs:
            print("æˆåŠŸè®¿é—®ç½‘ç«™ï¼Œä½†åœ¨é¡µé¢ä¸Šæœªè§£æå‡ºä»»ä½•èŒä½ä¿¡æ¯ã€‚å¯èƒ½æ˜¯CSSé€‰æ‹©å™¨éœ€è¦å†æ¬¡æ›´æ–°ã€‚")
        else:
            print(f"âœ… [Selenium] æˆåŠŸæ‰¾åˆ° {len(scraped_jobs)} ä¸ªç›¸å…³èŒä½ã€‚")
            
        self.job_postings = scraped_jobs
        driver.quit()
        return scraped_jobs
        
    def tool_optimize_resume(self, job_description: str) -> str:
        # ... (æ­¤å‡½æ•°åŠåç»­å‡½æ•°æ— éœ€ä¿®æ”¹) ...
        print("\nâœ¨ æ­£åœ¨ä¸ºæ‚¨ç”Ÿæˆå®šåˆ¶åŒ–ç®€å†ä¼˜åŒ–å»ºè®®...")
        prompt = f"""
        ä½ æ˜¯ä¸€ä½é¡¶çº§çš„ITèŒä¸šè§„åˆ’å¸ˆå’Œç®€å†ä¼˜åŒ–ä¸“å®¶ã€‚
        è¯·ä¸¥æ ¼æŒ‰ç…§ä¸‹é¢çš„ã€å²—ä½æè¿°ã€‘ï¼Œä¼˜åŒ–è¿™ä»½ã€åŸå§‹ç®€å†ã€‘ã€‚

        ä½ çš„ä»»åŠ¡æ˜¯ï¼š
        1.  **ç²¾å‡†åŒ¹é…**: ä¿®æ”¹ã€åŸå§‹ç®€å†ã€‘ä¸­çš„é¡¹ç›®ç»å†å’ŒæŠ€èƒ½æè¿°ï¼Œä½¿å…¶è¯­è¨€é£æ ¼å’ŒæŠ€æœ¯å…³é”®è¯ä¸ã€å²—ä½æè¿°ã€‘é«˜åº¦å¯¹é½ã€‚
        2.  **æˆæœå¯¼å‘**: å°†é¡¹ç›®ç»å†ä¸­çš„æè¿°ä»â€œåšäº†ä»€ä¹ˆâ€æ”¹ä¸ºâ€œå–å¾—äº†ä»€ä¹ˆæˆå°±â€ã€‚å¦‚æœå¯ä»¥ï¼Œå°è¯•ç”¨æ•°å­—æ¥é‡åŒ–æˆæœï¼ˆä¾‹å¦‚ï¼šå°†å¤„ç†æ•ˆç‡æå‡äº†15%ï¼‰ã€‚
        3.  **çªå‡ºäº®ç‚¹**: æ ¹æ®ã€å²—ä½æè¿°ã€‘çš„è¦æ±‚ï¼Œå°†ç®€å†ä¸­æœ€ç›¸å…³çš„æŠ€èƒ½å’Œé¡¹ç›®ç»éªŒè°ƒæ•´åˆ°æ›´çªå‡ºçš„ä½ç½®ã€‚
        4.  **ç›´æ¥è¾“å‡ºä¼˜åŒ–åçš„ç®€å†**: ä¸è¦è¯´â€œä»¥ä¸‹æ˜¯ä¼˜åŒ–åçš„ç®€å†â€ä¹‹ç±»çš„è¯ï¼Œç›´æ¥ç»™æˆ‘ä¼˜åŒ–åçš„å®Œæ•´ç®€å†æ–‡æœ¬ã€‚

        ---
        ã€å²—ä½æè¿°ã€‘:
        {job_description}
        ---
        ã€åŸå§‹ç®€å†ã€‘:
        {self.resume_text}
        ---

        è¯·è¾“å‡ºä¼˜åŒ–åçš„ç®€å†å…¨æ–‡ï¼š
        """
        try:
            response = self.llm.generate_content(prompt)
            return response.text
        except Exception as e:
            return f"è°ƒç”¨AIæ¨¡å‹å¤±è´¥: {e}"

    def tool_supplement_materials(self, job_description: str) -> str:
        # ... (æ­¤å‡½æ•°æ— éœ€ä¿®æ”¹) ...
        print("\nğŸ”¬ æ­£åœ¨åˆ†ææ‚¨çš„æŠ€èƒ½çŸ­æ¿å¹¶æä¾›å­¦ä¹ å»ºè®®...")
        prompt = f"""
        ä½ æ˜¯ä¸€ä½èµ„æ·±çš„è½¯ä»¶å·¥ç¨‹å¸ˆé¢è¯•å®˜ã€‚è¯·æ·±å…¥å¯¹æ¯”åˆ†æä¸‹é¢çš„ã€æ±‚èŒè€…ç®€å†ã€‘å’Œã€å²—ä½è¦æ±‚ã€‘ï¼Œä»¥å¸®åŠ©è¿™ä½æ±‚èŒè€…å‡†å¤‡é¢è¯•ã€‚

        ä½ çš„ä»»åŠ¡æ˜¯ç”Ÿæˆä¸€ä»½è¯¦ç»†çš„ã€æ±‚èŒè€…èƒ½åŠ›æå‡å’Œé¢è¯•å‡†å¤‡æŠ¥å‘Šã€‘ï¼ŒåŒ…å«ä»¥ä¸‹ä¸‰ä¸ªéƒ¨åˆ†ï¼Œå¹¶ä¸¥æ ¼ä½¿ç”¨Markdownæ ¼å¼åŒ–è¾“å‡ºï¼š

        **1. æŠ€èƒ½å·®è·åˆ†æ (Gap Analysis):**
           - æ˜ç¡®åˆ—å‡ºã€å²—ä½è¦æ±‚ã€‘ä¸­æåˆ°ï¼Œä½†ã€æ±‚èŒè€…ç®€å†ã€‘ä¸­å®Œå…¨æ²¡æœ‰ä½“ç°æˆ–ä½“ç°ä¸è¶³çš„å…³é”®æŠ€èƒ½ç‚¹ã€‚
           - å¯¹æ¯ä¸ªæŠ€èƒ½ç‚¹è¿›è¡Œç®€è¦è¯´æ˜ï¼Œè§£é‡Šä¸ºä»€ä¹ˆå®ƒå¯¹è¿™ä¸ªå²—ä½å¾ˆé‡è¦ã€‚

        **2. çŸ¥è¯†å¼ºåŒ–è·¯å¾„ (Learning Path):**
           - é’ˆå¯¹æ¯ä¸€ä¸ªçŸ­æ¿ï¼Œæä¾›ä¸€ä¸ªå…·ä½“çš„ã€å¯æ‰§è¡Œçš„å­¦ä¹ è®¡åˆ’ã€‚
           - ä¾‹å¦‚ï¼šæ¨èéœ€è¦å­¦ä¹ çš„ç‰¹å®šæŠ€æœ¯åº“ã€å€¼å¾—çœ‹çš„åœ¨çº¿è¯¾ç¨‹ï¼ˆåªéœ€è¯´å‡ºè¯¾ç¨‹ä¸»é¢˜å’Œå¹³å°ï¼Œå¦‚ Coursera ä¸Šçš„ "Advanced Python"ï¼‰ï¼Œæˆ–å»ºè®®å®Œæˆçš„å®æˆ˜é¡¹ç›®ç±»å‹ã€‚

        **3. æ ¸å¿ƒé¢è¯•é¢˜é¢„æµ‹ (Interview Prep):**
           - åˆ—å‡º3-5ä¸ªé’ˆå¯¹è¯¥å²—ä½æœ€å¯èƒ½è¢«é—®åˆ°çš„æ ¸å¿ƒæŠ€æœ¯é—®é¢˜ï¼ˆâ€œå…«è‚¡æ–‡â€ï¼‰ã€‚
           - ä¸ºæ¯ä¸ªé—®é¢˜æä¾›ä¸€ä¸ªç®€æ´ä½†ç²¾å‡†çš„å›ç­”æ€è·¯æˆ–è¦ç‚¹ã€‚

        ---
        ã€å²—ä½è¦æ±‚ã€‘:
        {job_description}
        ---
        ã€æ±‚èŒè€…ç®€å†ã€‘:
        {self.resume_text}
        ---

        è¯·å¼€å§‹ç”ŸæˆæŠ¥å‘Šï¼š
        """
        try:
            response = self.llm.generate_content(prompt)
            return response.text
        except Exception as e:
            return f"è°ƒç”¨AIæ¨¡å‹å¤±è´¥: {e}"

    def run(self, job_query: str):
        # ... (æ­¤å‡½æ•°æ— éœ€ä¿®æ”¹) ...
        self.load_resume()
        self.tool_search_jobs(job_query)
        if not self.job_postings:
            print("æœªèƒ½æ‰¾åˆ°ç›¸å…³èŒä½ï¼Œç¨‹åºé€€å‡ºã€‚")
            return

        target_job = self.job_postings[0]
        print(f"\nğŸ¯ å·²é”å®šç›®æ ‡èŒä½ï¼šã€{target_job['title']}ã€‘ at ã€{target_job['company']}ã€‘")
        print("-------------------- èŒä½æè¿°é¢„è§ˆ --------------------")
        print(textwrap.fill(target_job['description'], width=80))
        print("----------------------------------------------------\n")

        optimized_resume = self.tool_optimize_resume(target_job['description'])
        print("\n\n=============== ğŸš€ ä¼˜åŒ–åçš„ç®€å†å»ºè®® ================")
        print(optimized_resume)
        print("====================================================\n\n")

        gap_analysis_report = self.tool_supplement_materials(target_job['description'])
        print("=============== ğŸ’¡ ä¸ªäººèƒ½åŠ›æå‡æŠ¥å‘Š ================")
        print(gap_analysis_report)
        print("====================================================")


# --- ä¸»ç¨‹åºå…¥å£ ---
if __name__ == '__main__':
    agent = JobSeekingAgent(llm_model=llm)
    agent.run("Python Developer")